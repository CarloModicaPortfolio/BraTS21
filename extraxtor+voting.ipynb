{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e859661b",
   "metadata": {
    "papermill": {
     "duration": 0.017389,
     "end_time": "2021-10-22T00:46:14.949632",
     "exception": false,
     "start_time": "2021-10-22T00:46:14.932243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5457c24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:15.067187Z",
     "iopub.status.busy": "2021-10-22T00:46:15.066392Z",
     "iopub.status.idle": "2021-10-22T00:46:25.364325Z",
     "shell.execute_reply": "2021-10-22T00:46:25.363754Z",
     "shell.execute_reply.started": "2021-10-22T00:39:04.630669Z"
    },
    "papermill": {
     "duration": 10.39828,
     "end_time": "2021-10-22T00:46:25.364474",
     "exception": false,
     "start_time": "2021-10-22T00:46:14.966194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 00:46:16.688095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pydicom # Handle MRI images\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "import cv2  # OpenCV - https://docs.opencv.org/master/d6/d00/tutorial_py_root.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4abfdb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:25.404282Z",
     "iopub.status.busy": "2021-10-22T00:46:25.403504Z",
     "iopub.status.idle": "2021-10-22T00:46:25.405428Z",
     "shell.execute_reply": "2021-10-22T00:46:25.405854Z",
     "shell.execute_reply.started": "2021-10-22T00:39:04.851981Z"
    },
    "papermill": {
     "duration": 0.02333,
     "end_time": "2021-10-22T00:46:25.405973",
     "exception": false,
     "start_time": "2021-10-22T00:46:25.382643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752bd066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:25.443219Z",
     "iopub.status.busy": "2021-10-22T00:46:25.442730Z",
     "iopub.status.idle": "2021-10-22T00:46:30.747753Z",
     "shell.execute_reply": "2021-10-22T00:46:30.747225Z",
     "shell.execute_reply.started": "2021-10-22T00:39:05.134906Z"
    },
    "papermill": {
     "duration": 5.325648,
     "end_time": "2021-10-22T00:46:30.747893",
     "exception": false,
     "start_time": "2021-10-22T00:46:25.422245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 00:46:25.473610: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-22 00:46:25.476970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-22 00:46:25.516625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:25.517290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-10-22 00:46:25.517358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-22 00:46:25.543868: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-22 00:46:25.543978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-22 00:46:25.559459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-22 00:46:25.568427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-22 00:46:25.594303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-22 00:46:25.601663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-22 00:46:25.605200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-22 00:46:25.605420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:25.606174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:25.607740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-22 00:46:25.608225: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-22 00:46:25.608466: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-22 00:46:25.608654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:25.609223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
      "2021-10-22 00:46:25.609272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-22 00:46:25.609302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-22 00:46:25.609324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-22 00:46:25.609345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-22 00:46:25.609365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-22 00:46:25.609401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-22 00:46:25.609426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-22 00:46:25.609448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-22 00:46:25.609553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:25.610191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:25.610726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2021-10-22 00:46:25.611757: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-22 00:46:27.062164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-22 00:46:27.062216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-10-22 00:46:27.062226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-10-22 00:46:27.064995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:27.065801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:27.066453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-22 00:46:27.067067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "base_resnet = Xception(    \n",
    "    weights= '../input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    pooling='avg',\n",
    "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
    "    include_top=False)\n",
    "#base_resnet.load_weights('../input/NASNet-large-no-top/NASNet-large-no-top.h5')\n",
    "#base_resnet.summary()\n",
    "\n",
    "\n",
    "base_resnet.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392a3ad",
   "metadata": {
    "papermill": {
     "duration": 0.017988,
     "end_time": "2021-10-22T00:46:30.785792",
     "exception": false,
     "start_time": "2021-10-22T00:46:30.767804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration, Constants, Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9cb483d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:30.827359Z",
     "iopub.status.busy": "2021-10-22T00:46:30.826775Z",
     "iopub.status.idle": "2021-10-22T00:46:30.830738Z",
     "shell.execute_reply": "2021-10-22T00:46:30.830153Z",
     "shell.execute_reply.started": "2021-10-22T00:36:13.466651Z"
    },
    "papermill": {
     "duration": 0.02666,
     "end_time": "2021-10-22T00:46:30.830854",
     "exception": false,
     "start_time": "2021-10-22T00:46:30.804194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = Path('../input/rsna-miccai-brain-tumor-radiogenomic-classification/')\n",
    "mri_types = [\"FLAIR\", \"T1w\", \"T2w\", \"T1wCE\"]\n",
    "excluded_images = [109, 123, 709] # Bad images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3790c9",
   "metadata": {
    "papermill": {
     "duration": 0.017353,
     "end_time": "2021-10-22T00:46:30.865630",
     "exception": false,
     "start_time": "2021-10-22T00:46:30.848277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de0c0b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:30.904076Z",
     "iopub.status.busy": "2021-10-22T00:46:30.903424Z",
     "iopub.status.idle": "2021-10-22T00:46:30.933356Z",
     "shell.execute_reply": "2021-10-22T00:46:30.932928Z",
     "shell.execute_reply.started": "2021-10-22T00:36:14.220438Z"
    },
    "papermill": {
     "duration": 0.051177,
     "end_time": "2021-10-22T00:46:30.933460",
     "exception": false,
     "start_time": "2021-10-22T00:46:30.882283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: Rows=582, Columns=2\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_dir / \"train_labels.csv\",\n",
    "#                        index='id',\n",
    "#                       nrows=100000\n",
    "                      )\n",
    "test_df = pd.read_csv(data_dir / \"sample_submission.csv\")\n",
    "sample_submission = pd.read_csv(data_dir / \"sample_submission.csv\")\n",
    "\n",
    "#padnda dataframe with one coloumn ID the other the MGMT presence (1 yes 0 no)\n",
    "train_df = train_df[~train_df.BraTS21ID.isin(excluded_images)]\n",
    "\n",
    "print(f\"train data: Rows={train_df.shape[0]}, Columns={train_df.shape[1]}\")\n",
    "# print(f\"test data : Rows={test_df.shape[0]}, Columns={test_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d573ba",
   "metadata": {
    "papermill": {
     "duration": 0.016848,
     "end_time": "2021-10-22T00:46:30.967507",
     "exception": false,
     "start_time": "2021-10-22T00:46:30.950659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af4ecd",
   "metadata": {
    "papermill": {
     "duration": 0.01688,
     "end_time": "2021-10-22T00:46:31.001296",
     "exception": false,
     "start_time": "2021-10-22T00:46:30.984416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### There's a version that converts into grayscale: \n",
    "\n",
    "- https://www.kaggle.com/smoschou55/advanced-eda-brain-tumor-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0aeb54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:31.046356Z",
     "iopub.status.busy": "2021-10-22T00:46:31.045832Z",
     "iopub.status.idle": "2021-10-22T00:46:31.049119Z",
     "shell.execute_reply": "2021-10-22T00:46:31.049569Z",
     "shell.execute_reply.started": "2021-10-22T00:45:03.223805Z"
    },
    "papermill": {
     "duration": 0.031339,
     "end_time": "2021-10-22T00:46:31.049695",
     "exception": false,
     "start_time": "2021-10-22T00:46:31.018356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dicom(path, voi_lut=True, fix_monochrome=True, remove_black_boundary=True, augmentation=False):\n",
    "    global IMAGE_SIZE\n",
    "    dicom = pydicom.read_file(path)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    #if remove_black_boundary: # we get slightly more details\n",
    "    #    (x, y) = np.where(data > 0)\n",
    "    #    if len(x) > 0 and len(y) > 0:\n",
    "    #        x_mn = np.min(x)\n",
    "    #        x_mx = np.max(x)\n",
    "    #        y_mn = np.min(y)\n",
    "    #        y_mx = np.max(y)\n",
    "    #        if (x_mx - x_mn) > 10 and (y_mx - y_mn) > 10:\n",
    "    #            data = data[:,np.min(y):np.max(y)]\n",
    "    \n",
    "    #check if the image is all black:\n",
    "    if np.sum(data) < 0.01:\n",
    "        #print(\"LOADING BLACK IMAGE\")\n",
    "        remove_black_boundary = False\n",
    "        \n",
    "   \n",
    "    if remove_black_boundary:\n",
    "        data_no_boundary_1 = []\n",
    "        data_no_boundary_2 = []\n",
    "        #remove black rows\n",
    "        for i in range(len(data)):\n",
    "            if np.sum(data[i]) > 0.01:\n",
    "                data_no_boundary_1.append(data[i])\n",
    "        data_no_boundary_1 = np.array(data_no_boundary_1)\n",
    "        for j in range(np.shape(data_no_boundary_1)[1]):\n",
    "            if np.sum(data_no_boundary_1[:,j]) != 0:\n",
    "                data_no_boundary_2.append(data_no_boundary_1[:,j])\n",
    "        data_no_boundary_2 = np.array(data_no_boundary_2).T\n",
    "        data = data_no_boundary_2\n",
    "        \n",
    "    data = np.array(data)\n",
    "    data = cv2.resize(data, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    data = cv2.cvtColor(data,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    return data, remove_black_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38ec23a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:31.103340Z",
     "iopub.status.busy": "2021-10-22T00:46:31.102671Z",
     "iopub.status.idle": "2021-10-22T00:46:31.112922Z",
     "shell.execute_reply": "2021-10-22T00:46:31.113296Z",
     "shell.execute_reply.started": "2021-10-22T00:45:03.496880Z"
    },
    "papermill": {
     "duration": 0.046642,
     "end_time": "2021-10-22T00:46:31.113430",
     "exception": false,
     "start_time": "2021-10-22T00:46:31.066788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `SimplexNoiseAlpha()` is deprecated. Use `BlendAlphaSimplexNoise` instead. SimplexNoiseAlpha is deprecated. Use BlendAlphaSimplexNoise instead. The order of parameters is the same. Parameter 'first' was renamed to 'foreground'. Parameter 'second' was renamed to 'background'.\n",
      "  warn_deprecated(msg, stacklevel=3)\n",
      "/opt/conda/lib/python3.7/site-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `FrequencyNoiseAlpha()` is deprecated. Use `BlendAlphaFrequencyNoise` instead. FrequencyNoiseAlpha is deprecated. Use BlendAlphaFrequencyNoise instead. The order of parameters is the same. Parameter 'first' was renamed to 'foreground'. Parameter 'second' was renamed to 'background'.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.2, aug)\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "        # crop images by -5% to 10% of their height/width\n",
    "        sometimes(iaa.CropAndPad(\n",
    "            percent=(-0.05, 0.05),\n",
    "            pad_mode=ia.ALL,\n",
    "            pad_cval=(0, 255)\n",
    "        )),\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "        )),\n",
    "        # execute 0 to 5 of the following (less important) augmenters per image\n",
    "        # don't execute all of them, as that would often be way too strong\n",
    "        iaa.SomeOf((0, 5),\n",
    "            [\n",
    "                sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                # search either for all edges or for directed edges,\n",
    "                # blend the result with the original image using a blobby mask\n",
    "                iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                    iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                \n",
    "                # either change the brightness of the whole image (sometimes\n",
    "                # per channel) or change the brightness of subareas\n",
    "                iaa.OneOf([\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                    iaa.FrequencyNoiseAlpha(\n",
    "                        exponent=(-4, 0),\n",
    "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
    "                        second=iaa.LinearContrast((0.5, 2.0))\n",
    "                    )\n",
    "                ]),\n",
    "                iaa.LinearContrast((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    random_order=True\n",
    ")\n",
    "#slices_aug = seq(images=slices.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c87432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:31.156178Z",
     "iopub.status.busy": "2021-10-22T00:46:31.155389Z",
     "iopub.status.idle": "2021-10-22T00:46:31.161487Z",
     "shell.execute_reply": "2021-10-22T00:46:31.161901Z",
     "shell.execute_reply.started": "2021-10-22T00:45:03.771897Z"
    },
    "papermill": {
     "duration": 0.031259,
     "end_time": "2021-10-22T00:46:31.162023",
     "exception": false,
     "start_time": "2021-10-22T00:46:31.130764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "radius = 60\n",
    "def get_all_image_paths(brats21id, image_type, folder='train'): \n",
    "    '''\n",
    "    Returns an arry of all the images of a particular type for a particular patient ID\n",
    "    '''\n",
    "    assert(image_type in mri_types)\n",
    "    \n",
    "    patient_path = os.path.join(\n",
    "        \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/%s/\" % folder, \n",
    "        str(brats21id).zfill(5),\n",
    "    )\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n",
    "        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "    )\n",
    "    \n",
    "    num_images = len(paths)\n",
    "    middle = num_images//2\n",
    "    \n",
    "    return (paths)\n",
    "\n",
    "def get_all_images(brats21id, image_type, folder='train'):\n",
    "    images = []\n",
    "    for path in get_all_image_paths(brats21id, image_type, folder):\n",
    "        image, remove_black = load_dicom(path)\n",
    "        if remove_black == True:\n",
    "            images.append(image)\n",
    "            \n",
    "    if len(images) > radius:\n",
    "        indices = random.sample(range(len(images)), radius)\n",
    "        images = [images[i] for i in sorted(indices)]\n",
    "    else:\n",
    "        m = int(radius/len(images))\n",
    "        rest = radius - m*len(images)\n",
    "        images_ = copy.copy(images)\n",
    "      \n",
    "        for k in range(1, m):\n",
    "            j = 0\n",
    "            for image in images_:\n",
    "                images.insert(j*(k+1), seq(images = image)) \n",
    "                j +=1\n",
    "        \n",
    "        for _ in range(rest):\n",
    "            rndm = random.randint(0, len(images_)-1)\n",
    "            images.insert(rndm, seq(images = images[rndm]))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74e602",
   "metadata": {
    "papermill": {
     "duration": 0.017224,
     "end_time": "2021-10-22T00:46:31.197414",
     "exception": false,
     "start_time": "2021-10-22T00:46:31.180190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Images We Will Need + Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be114be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:31.239614Z",
     "iopub.status.busy": "2021-10-22T00:46:31.238825Z",
     "iopub.status.idle": "2021-10-22T00:46:31.240905Z",
     "shell.execute_reply": "2021-10-22T00:46:31.241270Z",
     "shell.execute_reply.started": "2021-10-22T00:45:04.350250Z"
    },
    "papermill": {
     "duration": 0.026785,
     "end_time": "2021-10-22T00:46:31.241396",
     "exception": false,
     "start_time": "2021-10-22T00:46:31.214611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_data_for_train(image_size=IMAGE_SIZE):\n",
    "    global train_df\n",
    "    global mri_types\n",
    "    global base_resnet\n",
    "    y = []\n",
    "    train_ids = []\n",
    "    listMatrix = []\n",
    "    for i in tqdm(train_df.index):\n",
    "        #print(\"INIZIO CICLO: \", i)\n",
    "        img_s = []\n",
    "        for mri in mri_types:\n",
    "            #print(\"TIPO DI IMMAGINE: \", mri)\n",
    "            x = train_df.loc[i]\n",
    "            #here we have all the images that have just one ID. We want more, we can performe data augmentation. \n",
    "            images = get_all_images(int(x['BraTS21ID']), mri, 'train')\n",
    "            #print(\"IMAGE\")\n",
    "            #print(mri)\n",
    "            #print(np.shape(images[0]))\n",
    "            #plt.imshow(images[0])\n",
    "            #plt.show()\n",
    "            #print(\"\\n\")\n",
    "            img_s += images\n",
    "            #print(\"NUMERO IMMAGINI xTIPO xPAZIENTE DOPO AUMENTO: \", len(images))\n",
    "            #images_augmented = perform_data_augmentation(images)\n",
    "        label = x['MGMT_value']\n",
    "        IMGS = np.array(img_s)\n",
    "        IMGS = tf.expand_dims(IMGS, axis = -1)\n",
    "        #IMGS = tf.keras.applications.xception.preprocess_input(IMGS)\n",
    "        PatientMatrix = base_resnet.predict(IMGS)\n",
    "        print(np.shape(PatientMatrix))\n",
    "        listMatrix.append(PatientMatrix)\n",
    "\n",
    "        y.append(label)\n",
    "        train_ids.append(int(x['BraTS21ID']))\n",
    "    assert(len(listMatrix) == len(y))\n",
    "    return listMatrix, y, train_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a734d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T00:46:31.279745Z",
     "iopub.status.busy": "2021-10-22T00:46:31.278979Z",
     "iopub.status.idle": "2021-10-22T04:17:25.258331Z",
     "shell.execute_reply": "2021-10-22T04:17:25.258757Z",
     "shell.execute_reply.started": "2021-10-22T00:45:04.764898Z"
    },
    "papermill": {
     "duration": 12654.000294,
     "end_time": "2021-10-22T04:17:25.258921",
     "exception": false,
     "start_time": "2021-10-22T00:46:31.258627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ac08de9d0e417a8507581e1c0fe73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/imgaug/augmenters/base.py:38: SuspiciousMultiImageShapeWarning: You provided a numpy array of shape (128, 128, 3) as a multi-image augmentation input, which was interpreted as (N, H, W). The last dimension however has value 1 or 3, which indicates that you provided a single image with shape (H, W, C) instead. If that is the case, you should use e.g. augmenter(image=<your input>) or augment_image(<your input>) -- note the singular 'image' instead of 'imageS'. Otherwise your single input image will be interpreted as multiple images of shape (H, W) during augmentation.\n",
      "  category=SuspiciousMultiImageShapeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/imgaug/augmenters/segmentation.py:272: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  image, n_segments=n_segments_samples[i], compactness=10)\n",
      "2021-10-22 00:46:58.160565: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-10-22 00:46:58.172303: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2000189999 Hz\n",
      "2021-10-22 00:46:58.851638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-22 00:47:04.127016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-22 00:47:04.862470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n",
      "(240, 2048)\n"
     ]
    }
   ],
   "source": [
    "listMatrix, y, train_ids = get_all_data_for_train(image_size = IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a6b90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T04:17:25.596365Z",
     "iopub.status.busy": "2021-10-22T04:17:25.595767Z",
     "iopub.status.idle": "2021-10-22T04:17:25.598476Z",
     "shell.execute_reply": "2021-10-22T04:17:25.598922Z",
     "shell.execute_reply.started": "2021-10-22T00:42:51.333491Z"
    },
    "papermill": {
     "duration": 0.174182,
     "end_time": "2021-10-22T04:17:25.599054",
     "exception": false,
     "start_time": "2021-10-22T04:17:25.424872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"inputs = kr.Input(shape=input_shape, name='input')\\n\\nx = layers.Conv2D(filters, (3, 3), activation='relu', strides=2, padding='same')(inputs)\\nx = layers.Conv2D(filters*2, (3, 3), activation='relu', strides=2, padding='same')(x)\\n\\n# shape info needed to build decoder model\\nshape = x.get_shape().as_list()\\n\\n# generate latent vector Q(z|X)\\nx = layers.Flatten()(x)\\nx = layers.Dense(16, activation='relu')(x)\\nz_mean = layers.Dense(latent_dim, name='z_mean')(x)\\nz_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\\n\\nz = layers.Lambda(sampling, name='z')([z_mean, z_log_var])\\n\\n# instantiate encoder model\\nencoder = kr.Model(inputs, [z_mean, z_log_var, z], name='encoder')\\nencoder.summary()\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"inputs = kr.Input(shape=input_shape, name='input')\n",
    "\n",
    "x = layers.Conv2D(filters, (3, 3), activation='relu', strides=2, padding='same')(inputs)\n",
    "x = layers.Conv2D(filters*2, (3, 3), activation='relu', strides=2, padding='same')(x)\n",
    "\n",
    "# shape info needed to build decoder model\n",
    "shape = x.get_shape().as_list()\n",
    "\n",
    "# generate latent vector Q(z|X)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation='relu')(x)\n",
    "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = layers.Lambda(sampling, name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = kr.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55599590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T04:17:25.932423Z",
     "iopub.status.busy": "2021-10-22T04:17:25.931474Z",
     "iopub.status.idle": "2021-10-22T04:17:30.683368Z",
     "shell.execute_reply": "2021-10-22T04:17:30.682917Z",
     "shell.execute_reply.started": "2021-10-22T00:42:51.335833Z"
    },
    "papermill": {
     "duration": 4.921894,
     "end_time": "2021-10-22T04:17:30.683495",
     "exception": false,
     "start_time": "2021-10-22T04:17:25.761601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 04:17:28.146967: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 914227200 exceeds 10% of free system memory.\n",
      "2021-10-22 04:17:29.521834: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1144258560 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# PRocess feature vectors\n",
    "X_2 = np.asarray(listMatrix)\n",
    "y_ = np.asarray(y)\n",
    "_train_ids = np.array(train_ids)\n",
    "X_train, X_valid, y_train, y_valid, ids_train, ids_valid = train_test_split(X_2, y_, _train_ids, test_size=0.2, random_state=42)\n",
    "y_train = to_categorical(y_train)\n",
    "y_valid = to_categorical(y_valid)\n",
    "X_train = tf.expand_dims(X_train, axis = -1)\n",
    "X_valid = tf.expand_dims(X_valid, axis = -1)\n",
    "X_ = tf.expand_dims(X_2, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ce545d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T04:17:31.021206Z",
     "iopub.status.busy": "2021-10-22T04:17:31.020390Z",
     "iopub.status.idle": "2021-10-22T04:17:31.022964Z",
     "shell.execute_reply": "2021-10-22T04:17:31.022487Z",
     "shell.execute_reply.started": "2021-10-22T00:42:51.338160Z"
    },
    "papermill": {
     "duration": 0.174313,
     "end_time": "2021-10-22T04:17:31.023071",
     "exception": false,
     "start_time": "2021-10-22T04:17:30.848758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_data_for_test(image_size=IMAGE_SIZE):\n",
    "    global test_df\n",
    "    global mri_types\n",
    "    global base_resnet\n",
    "    test_ids = []\n",
    "    test_listMatrix = []\n",
    "    for i in tqdm(test_df.index):\n",
    "        img_s = []\n",
    "        for mri in mri_types:\n",
    "            x = test_df.loc[i]\n",
    "            images = get_all_images(int(x['BraTS21ID']), mri, 'test')\n",
    "            img_s += images\n",
    "        label = x['MGMT_value']\n",
    "        IMGS = np.array(img_s)\n",
    "        IMGS = tf.expand_dims(IMGS, axis = -1)\n",
    "                \n",
    "        test_PatientMatrix = base_resnet.predict(IMGS)\n",
    "        test_listMatrix.append(test_PatientMatrix)\n",
    "        test_ids.append(int(x['BraTS21ID']))\n",
    "\n",
    "    return test_listMatrix, test_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb2749c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T04:17:31.364139Z",
     "iopub.status.busy": "2021-10-22T04:17:31.363339Z",
     "iopub.status.idle": "2021-10-22T04:49:22.674674Z",
     "shell.execute_reply": "2021-10-22T04:49:22.674159Z",
     "shell.execute_reply.started": "2021-10-22T00:42:51.340016Z"
    },
    "papermill": {
     "duration": 1911.488418,
     "end_time": "2021-10-22T04:49:22.674812",
     "exception": false,
     "start_time": "2021-10-22T04:17:31.186394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f5955a84c84644a41546bfd0297dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_listMatrix, test_ids = get_all_data_for_test(image_size = IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fe9f76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T04:49:23.071829Z",
     "iopub.status.busy": "2021-10-22T04:49:23.070855Z",
     "iopub.status.idle": "2021-10-22T04:49:23.480935Z",
     "shell.execute_reply": "2021-10-22T04:49:23.481705Z",
     "shell.execute_reply.started": "2021-10-22T00:42:51.343551Z"
    },
    "papermill": {
     "duration": 0.617846,
     "end_time": "2021-10-22T04:49:23.481867",
     "exception": false,
     "start_time": "2021-10-22T04:49:22.864021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 240, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_2_test = np.asarray(test_listMatrix)\n",
    "print(np.shape(X_2_test))\n",
    "# PRocess feature vectors\n",
    "_test_ids = np.array(test_ids)\n",
    "X_test= tf.expand_dims(X_2_test, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4497a1",
   "metadata": {
    "papermill": {
     "duration": 0.181905,
     "end_time": "2021-10-22T04:49:23.923489",
     "exception": false,
     "start_time": "2021-10-22T04:49:23.741584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d6ed90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T04:49:24.317783Z",
     "iopub.status.busy": "2021-10-22T04:49:24.315736Z",
     "iopub.status.idle": "2021-10-22T05:00:05.171052Z",
     "shell.execute_reply": "2021-10-22T05:00:05.171492Z",
     "shell.execute_reply.started": "2021-10-20T19:11:26.190123Z"
    },
    "papermill": {
     "duration": 641.055042,
     "end_time": "2021-10-22T05:00:05.171660",
     "exception": false,
     "start_time": "2021-10-22T04:49:24.116618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-22 04:49:24.504012: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1144258560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(n_estimators=50,\n",
       "                                                     random_state=42)),\n",
       "                             ('ab', AdaBoostClassifier(random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X_for_voting = X_.numpy().reshape(X_.numpy().shape[0], -1)\n",
    "X_test_voting = X_test.numpy().reshape(X_test.numpy().shape[0], -1)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42,probability=True)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "ab_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "voting = VotingClassifier(\n",
    "             estimators=[#('lr', log_clf),\n",
    "                         ('rf', rnd_clf),\n",
    "                         #('svc', svm_clf),\n",
    "                         #('knn',knn_clf),\n",
    "                         ('ab', ab_clf)\n",
    "                        ],\n",
    "             voting='soft',\n",
    "             flatten_transform=True)\n",
    "\n",
    "voting.fit(X_for_voting,y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32baa649",
   "metadata": {
    "papermill": {
     "duration": 0.165296,
     "end_time": "2021-10-22T05:00:05.506273",
     "exception": false,
     "start_time": "2021-10-22T05:00:05.340977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predictions on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022f17b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T05:00:05.844377Z",
     "iopub.status.busy": "2021-10-22T05:00:05.843548Z",
     "iopub.status.idle": "2021-10-22T05:00:07.597447Z",
     "shell.execute_reply": "2021-10-22T05:00:07.597867Z",
     "shell.execute_reply.started": "2021-10-20T19:11:27.609004Z"
    },
    "papermill": {
     "duration": 1.926148,
     "end_time": "2021-10-22T05:00:07.598034",
     "exception": false,
     "start_time": "2021-10-22T05:00:05.671886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = voting.predict(X_test_voting)\n",
    "#pred = np.argmax(y_pred, axis=1) #\n",
    "\n",
    "result = pd.DataFrame(test_ids)\n",
    "result[1] = pred\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5ed252d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T05:00:07.947702Z",
     "iopub.status.busy": "2021-10-22T05:00:07.947137Z",
     "iopub.status.idle": "2021-10-22T05:00:07.972881Z",
     "shell.execute_reply": "2021-10-22T05:00:07.972329Z",
     "shell.execute_reply.started": "2021-10-20T19:11:27.628959Z"
    },
    "papermill": {
     "duration": 0.206967,
     "end_time": "2021-10-22T05:00:07.973009",
     "exception": false,
     "start_time": "2021-10-22T05:00:07.766042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>829</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>833</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1006</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BraTS21ID  MGMT_value\n",
       "0           1         1.0\n",
       "1          13         1.0\n",
       "2          15         1.0\n",
       "3          27         1.0\n",
       "4          37         1.0\n",
       "..        ...         ...\n",
       "82        826         0.0\n",
       "83        829         0.0\n",
       "84        833         0.0\n",
       "85        997         0.0\n",
       "86       1006         1.0\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns=['BraTS21ID','MGMT_value']\n",
    "\n",
    "result2 = result.groupby('BraTS21ID',as_index=False).mean()\n",
    "result2['BraTS21ID'] = sample_submission['BraTS21ID']\n",
    "\n",
    "# Rounding... 0.907866 -> 0.9\n",
    "result2['MGMT_value'] = result2['MGMT_value'].apply(lambda x:round(x*10)/10)\n",
    "# result2['MGMT_value'] = result2['MGMT_value'] # No rounding\n",
    "result2.to_csv('submission.csv',index=False)\n",
    "result2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15242.719968,
   "end_time": "2021-10-22T05:00:11.276411",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-22T00:46:08.556443",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "10bc1067b3bb460d8dc2a907911bb900": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b43bdbed9fa4723b5dd0cb334ffc91f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24c87c73c51c43ddad74b72a7aec1ca6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10bc1067b3bb460d8dc2a907911bb900",
       "placeholder": "",
       "style": "IPY_MODEL_923cdf176fc04ebcaf0ecb3c4c8b2c3d",
       "value": " 87/87 [31:51&lt;00:00, 24.33s/it]"
      }
     },
     "26be283c91cb4c199db0d789488b4354": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "29f5955a84c84644a41546bfd0297dd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_956d6b3c526b432696167fb316dd260a",
        "IPY_MODEL_434312454a0c41eaad1e0143e4278bf3",
        "IPY_MODEL_24c87c73c51c43ddad74b72a7aec1ca6"
       ],
       "layout": "IPY_MODEL_b73efa0d1ddf4744acd6df2877e14a8b"
      }
     },
     "3bee2a288575471ba296ba505e1337bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "434312454a0c41eaad1e0143e4278bf3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84eca5c956274165861ef4d41ada3d65",
       "max": 87.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bf823b6029eb44dcbce77a935624418b",
       "value": 87.0
      }
     },
     "560e6fc4238b44bf9b6f2f826f68a511": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5f540484be974ed1912ef912c400929e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3bee2a288575471ba296ba505e1337bd",
       "max": 582.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8ed60173e4444caea8e65f49951bf7f6",
       "value": 582.0
      }
     },
     "7ba6e585d30848ffacbbe7bf2f1e01fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f223177f54aa4bbb9a3ace57c62ed599",
       "placeholder": "",
       "style": "IPY_MODEL_560e6fc4238b44bf9b6f2f826f68a511",
       "value": "100%"
      }
     },
     "84eca5c956274165861ef4d41ada3d65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ed60173e4444caea8e65f49951bf7f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "923cdf176fc04ebcaf0ecb3c4c8b2c3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "956d6b3c526b432696167fb316dd260a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1b43bdbed9fa4723b5dd0cb334ffc91f",
       "placeholder": "",
       "style": "IPY_MODEL_963e19d42f604bf189ec39443e668cca",
       "value": "100%"
      }
     },
     "963e19d42f604bf189ec39443e668cca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9ff21ee594984c558be08fa9aa449f17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b73efa0d1ddf4744acd6df2877e14a8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b9ac08de9d0e417a8507581e1c0fe73a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7ba6e585d30848ffacbbe7bf2f1e01fe",
        "IPY_MODEL_5f540484be974ed1912ef912c400929e",
        "IPY_MODEL_dbc07c1b87d540458625181d326462b3"
       ],
       "layout": "IPY_MODEL_f602f061c91847109ff79d0b59c39647"
      }
     },
     "bf823b6029eb44dcbce77a935624418b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dbc07c1b87d540458625181d326462b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_26be283c91cb4c199db0d789488b4354",
       "placeholder": "",
       "style": "IPY_MODEL_9ff21ee594984c558be08fa9aa449f17",
       "value": " 582/582 [3:30:53&lt;00:00, 23.83s/it]"
      }
     },
     "f223177f54aa4bbb9a3ace57c62ed599": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f602f061c91847109ff79d0b59c39647": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
